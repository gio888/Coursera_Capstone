{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction/Business Problem\n",
    "The COVID-19 pandemic has taken an unprecedented toll globally, already affecting over 2M people, taking over 200K lives and, according to WEF, will likely cost the world 2 trillion USD in economic losses.\n",
    "\n",
    "Not all cities are affected by the virus the same way. We want to see how poverty incidence, a metric used to measured the level of poverty in a geographic area, is a predictor for severity of problem as measured by cases per capita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Section\n",
    "For this exercise, we will be using the following datasets:\n",
    "\n",
    "1. **Case Information dataset**\n",
    "    \n",
    "    **Source:** Philippine Department of Health. See https://www.doh.gov.ph/2019-nCoV\n",
    "    \n",
    "    **Description:** List of confirmed COVID-19 cases from the DOH Epidemiological Bureau.\n",
    "\n",
    "    **Dataset fields:**\n",
    "\t* CaseCode : Random code assigned for labelling cases\n",
    "\t* Age : Age\n",
    "\t* AgeGroup : Five-year age group\n",
    "\t* Sex : Sex\n",
    "\t* DateRepConf : Date publicly announced as confirmed case\n",
    "\t* DateRecover : Date recovered\n",
    "\t* DateDied : Date died\n",
    "\t* RemovalType : Type of removal (recovery or death)\n",
    "\t* DateRepRem : Date publicly announced as removed\n",
    "\t* Admitted : Binary variable indicating patient has been admitted to hospital\n",
    "\t* RegionRes : Region of residence\n",
    "\t* ProvCityRes : Province of residence\n",
    "\t* RegionPSGC : Philippine Standard Geographic Code of Region of Residence\n",
    "\t* ProvPSGC : Philippine Standard Geographic Code of Province of Residence\n",
    "\t* MunCityPSGC : Philippine Standard Geographic Code of Municipality or City of Residence\n",
    "\t* HealthStatus : Known current health status of patient (asymptomatic, mild, severe, critical, died, recovered)\n",
    "\t* Quarantined : Ever been home quarantined, not necessarily currently in home quarantine\n",
    "\n",
    "\n",
    "2. **Municipal and City Level Poverty Estimates**\n",
    "\n",
    "    **Source:** The Philippine Statistics Authority (PSA). See https://psa.gov.ph/content/psa-releases-2015-municipal-and-city-level-poverty-estimates\n",
    "\n",
    "    **Description:** This is a set of estimates using the small area estimation (SAE) technique. See https://psa.gov.ph/sites/default/files/Technical%20Notes%20on%202015%20SAE.pdf\n",
    "\n",
    "    **Dataset fields:**\n",
    "    * PSGC\n",
    "    * Region/Province\n",
    "    * Municipality/City\n",
    "    * Poverty Incidence\n",
    "\n",
    "\n",
    "2. **Philippine Standard Geographic Code (PSGC)**\n",
    "\n",
    "    **Source:** The Philippine Statistics Authority (PSA). See https://psa.gov.ph/content/psa-releases-2015-municipal-and-city-level-poverty-estimates\n",
    "\n",
    "    **Description:** The PSGC is a systematic classification and coding of geographic areas in the Philippines. It is based on the four (4) well-established hierarchical levels of geographical-political subdivisions of the country, namely, the administrative region, the province, the municipality/city, and the barangay.\n",
    "\n",
    "    **Dataset fields:**\n",
    "    \n",
    "    * Column \"Code\": PSGC Code\n",
    "    * Column \"Income Classification\"\n",
    "    * Column \"Class\" (Average Annual Income)\n",
    "        * Provinces:\n",
    "            * 1st\tP 450M or more\n",
    "            * 2nd\tP 360M or more but less than P 450M\n",
    "            * 3rd\tP 270M or more but less than P 360M\n",
    "            * 4th\tP 180M or more but less than P 270M\n",
    "            * 5th\tP 90M or more but less than P 180M\n",
    "            * 6th\tBelow P 90M\n",
    "        * Cities\n",
    "            * 1st\tP 400M or more\n",
    "            * 2nd\tP 320M or more but less than P 400M\n",
    "            * 3rd\tP 240M or more but less than P 320M\n",
    "            * 4th\tP 160M or more but less than P 240M\n",
    "            * 5th\tP 80M or more but less than P 160M\n",
    "            * 6th\tBelow P 80M\n",
    "        * Municipalities\n",
    "            * 1st\tP 55M or more\n",
    "            * 2nd\tP 45M or more but less than P 55M\n",
    "            * 3rd\tP 35M or more but less than P 45M\n",
    "            * 4th\tP 25M or more but less than P 35M\n",
    "            * 5th\tP 15M or more but less than P 25M\n",
    "            * 6th\tBelow P 15M\t\t\n",
    "    * Column \"Urban / Rural\"\n",
    "\t* Column \"Population\"\t\n",
    "    \n",
    "\n",
    "\n",
    "2. Geojson dataset of cities and municipalities in the Philippines. We will use this dataset to provide the mapping boundaries of the different cities and municipalities in the Philippines.\n",
    "\t* ID_0 : Unique ID 0\n",
    "\t* ISO : ISO Country Code\n",
    "\t* NAME_0 : Country Name\n",
    "\t* NAME_2 : Municipality or City Name\n",
    "\t* PROVINCE : Province Name\n",
    "\t* REGION : Regiona Name\n",
    "\t* geometry : Polygon, coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "section which represents the main component of the report where you discuss and describe any exploratory data analysis that you did, any inferential statistical testing that you performed, if any, and what machine learnings were used and why.\n",
    "\n",
    "We will use the CRISP-DM (Cross-Industry Process for Data Mining) methodology. The CRISP-DM methodology is well-proven methodology in data science. CRISP-DM loosely and iteratively follows six major phases:\n",
    "\n",
    "1. Business Understanding\n",
    "2. Data Understanding\n",
    "3. Data Preparation\n",
    "4. Modeling\n",
    "5. Evaluation\n",
    "6. Deployment\n",
    "\n",
    "As we have have covered #1 and #2 previously, we will continue with Data Preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We start by importing all necessary libraries and installing all dependencies for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plan\n",
    "\n",
    "- [Setup](#setup)\n",
    "    - import libraries\n",
    "- [Prepare data](#data_prep)\n",
    "    - DOH data\n",
    "        - explore\n",
    "        - clean\n",
    "        - select\n",
    "    - Poverty data\n",
    "        - explore\n",
    "        - clean\n",
    "        - select\n",
    "    - City index data\n",
    "        - explore\n",
    "        - clean\n",
    "        - select\n",
    "    - City Latlong\n",
    "        - load json\n",
    "        - explore\n",
    "        - clean\n",
    "        - select\n",
    "    - Merge data\n",
    "        - calculate case/pop as predicted variable\n",
    "        - calculate distance from manila as additional feature\n",
    "- Predict\n",
    "- Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"import_lib\"></a>\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json5 as json # library to handle JSON files\n",
    "import requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import folium # map rendering library\n",
    "import seaborn as sns\n",
    "import xlrd\n",
    "#import shapely\n",
    "#import fiona\n",
    "#import pyproj\n",
    "import geopandas as gpd\n",
    "\n",
    "#prep\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MaxAbsScaler, QuantileTransformer\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#validation libraries\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='data_prep'></a>\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOH Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We define the columns and their proper data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define column types\n",
    "col_types = {'Age' : 'float64', \n",
    "             'AgeGroup' : 'category', \n",
    "             'Sex' : 'category', \n",
    "             'RemovalType' : 'category', \n",
    "             'Admitted' : 'category', \n",
    "             'RegionRes' : 'category', \n",
    "             'ProvRes' : 'category', \n",
    "             'CityMunRes' : 'category', \n",
    "             'CityMuniPSGC' : 'category',\n",
    "             'BarangayRes' : 'category',\n",
    "             'BarangayPSGC' : 'category',\n",
    "             'HealthStatus' : 'category', \n",
    "             'Quarantined' : 'category', \n",
    "             'Pregnanttab' : 'category', \n",
    "             'ValidationStatus' : 'category'}\n",
    "col_date = [4, 5, 6, 7, 8, 19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We read the csv and load it into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_raw = pd.read_csv(\"DOH COVID Data Drop_ 20201013 - 04 Case Information.csv\", dtype = col_types, parse_dates = col_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploratory Data Analysis\n",
    "1. We do a quick check on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check our dataframe\n",
    "df_cases_raw.info()\n",
    "df_cases_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine unique values per column\n",
    "df_cases_raw.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Since our study wants to see if certain city statistic predicts cases, we will limit our variables to cases and cities, i.e CityMuniPSGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = df_cases_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = df_cases[['CaseCode','DateRepConf','CityMuniPSGC','CityMunRes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We drop the rows where we can't identify the cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Nan cities\n",
    "df_cases = df_cases.loc[-df_cases.CityMuniPSGC.isna(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For consistency, we rename CityMuniPSGC column to PSGC, which stands for Philippine Standard Geographic Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases = df_cases.rename(columns={\"CityMuniPSGC\": \"PSGC\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Then we group the dataframe into cities are represented by PSGC and count the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_by_city = df_cases.groupby(['PSGC','CityMunRes'])['CaseCode'].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Then we transform PSGC to standard nine-digit code for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_by_city.PSGC = df_cases_by_city.PSGC.str.replace('PH','')\n",
    "df_cases_by_city.rename(columns={\"CaseCode\": \"Cases\"}, inplace = True)\n",
    "df_cases_by_city.rename(columns={\"CityMunRes\": \"Name\"}, inplace = True)\n",
    "df_cases_by_city.sort_values('PSGC', inplace = True)\n",
    "df_cases_by_city.set_index('PSGC', inplace = True)\n",
    "#check\n",
    "df_cases_by_city.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_by_city = df_cases_by_city.loc[df_cases_by_city.Cases > 0,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cases_by_city.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poverty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read city stats\n",
    "df_poverty = pd.read_csv('City and Municipal-level Small Area Poverty Estimates_ 2009, 2012 and 2015_0.csv',\n",
    "                  skiprows = [0,1,2,3,4],\n",
    "                  encoding = \"ISO-8859-1\",\n",
    "                  names = ['PSGC_ID','Poverty Incidence'],\n",
    "                  usecols = [0,5],\n",
    "                  dtype = {'PSGC_ID':'object','Poverty Incidence':np.float16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NaN indexes\n",
    "df_poverty = df_poverty.loc[df_poverty.index.dropna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop other invalid rows\n",
    "df_poverty = df_poverty.loc[-df_poverty.PSGC_ID.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poverty['PSGC'] = df_poverty.PSGC_ID.str.zfill(6)\n",
    "df_poverty['PSGC'] = df_poverty.PSGC.str.ljust(9, '0')\n",
    "df_poverty.sort_values('PSGC', inplace = True)\n",
    "df_poverty.drop('PSGC_ID', axis =1, inplace = True)\n",
    "df_poverty.set_index('PSGC', inplace = True)\n",
    "df_poverty.sort_index(inplace = True)\n",
    "#check\n",
    "df_poverty.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load city data\n",
    "df_cityindex = pd.read_excel('PSGC 2Q 2020 Publication.xlsx',\n",
    "                    sheet_name = 'PSGC',\n",
    "                    usecols = [i for i in range(7)],\n",
    "                    names = ['PSGC',\n",
    "                             'Name',\n",
    "                             'Geographic Level',\n",
    "                             'City Class',\n",
    "                             'Income Classification',\n",
    "                             'Urban Rural',\n",
    "                             'Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter to only include cities, municipalities and sub municipalities\n",
    "df_cityindex = df_cityindex[df_cityindex['Geographic Level'].isin(['City','Mun','SubMun'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace NaNs with UNK\n",
    "df_cityindex = df_cityindex.fillna('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cityindex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cityindex.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cityindex['Geographic Level'].unique()\n",
    "\n",
    "df_cityindex['City Class'].unique()\n",
    "\n",
    "df_cityindex['Income Classification'].unique()\n",
    "\n",
    "df_cityindex['Urban Rural'].unique()\n",
    "\n",
    "df_cityindex['Income Classification'] = df_cityindex['Income Classification'].str.replace(r'\\*.*','')\n",
    "\n",
    "df_cityindex['Income Classification'] = df_cityindex['Income Classification'].str.replace(r' .*','')\n",
    "\n",
    "df_cityindex['Income Classification'] = df_cityindex['Income Classification'].str.replace('-','UNK')\n",
    "\n",
    "df_cityindex.drop('Urban Rural', axis =1, inplace = True)\n",
    "\n",
    "df_cityindex.PSGC = df_cityindex.PSGC.astype('str')\n",
    "\n",
    "df_cityindex.PSGC = df_cityindex.PSGC.str.zfill(9)\n",
    "\n",
    "df_cityindex = df_cityindex.astype(dtype = {'PSGC':'category', 'Name':'category',\n",
    "                    'Geographic Level':'category',\n",
    "                    'City Class':'category',\n",
    "                    'Income Classification':'category'})\n",
    "\n",
    "df_cityindex.sort_values('PSGC', inplace = True)\n",
    "\n",
    "df_cityindex.set_index('PSGC', inplace = True)\n",
    "\n",
    "df_cityindex.sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cityindex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cityindex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities Geodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geojson_path = 'https://github.com/faeldon/philippines-json-maps/tree/master/geojson/municties/medres'\n",
    "#geojson_path = 'https://github.com/justinelliotmeyers/official_philippines_shapefile_data_2016'\n",
    "#geojson_path = 'https://raw.githubusercontent.com/macoymejia/geojsonph/master/MuniCities/MuniCities.json'\n",
    "geojson_path = 'https://raw.githubusercontent.com/macoymejia/geojsonph/master/MuniCities/MuniCities.minimal.json'\n",
    "#geojson_path = '/Users/gio/Google Drive/Education/IBM Data Science Professional Certificate/Capstone/Coursera_Capstone/municities.json'\n",
    "df1 = gpd.read_file(geojson_path)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Centroid'] = df1.geometry.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Centroid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manila_loc = gpd.tools.geocode('Manila')\n",
    "manila_loc.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(manila_loc.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cent_gs'] = gpd.GeoSeries(df1.Centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.assign(Manila = manila_loc.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['dist_mnl'] = gpd.GeoSeries(df1.Centroid).distance(manila_loc.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sort_values(by = 'dist_mnl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.Centroid.GeoSeries.distance(manila_loc.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_cases_by_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.merge(df_cityindex, how = 'left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.merge(df_poverty, how = 'left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate case/pop as predicted variable\n",
    "calculate distance from manila as additional feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['Case Per Capita'] = df_merged.Cases/df_merged.Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "So now we have a dataset of cities and municipalities with feature statistics like city class, income classification, population and poverty incidences as possible predictors of cases per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.sort_values('Case Per Capita', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have explicitly changed NaNs to literal UNK categorical values, it would be worth checking how many UNKs are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change UNK for different columns\n",
    "for columns in df_merged.columns:\n",
    "    print(f'Percent UNK Column {columns} = {((sum(df_merged[columns] == \"UNK\"))/len(df_merged[columns])):.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This points to feature City Class to have mostly UNKs so let's get that off our list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[['Geographic Level','Income Classification',\n",
    "           'Population','Poverty Incidence','Case Per Capita']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Doing pairplots and correlattion analysis shows that of the features mentioned above, none is a strong predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df_merged)\n",
    "g.fig.suptitle(\"Pair Plot\", y=1.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_merged.corr(),annot=True,lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Separating the analysis by geographic level shows correlation to be stronger at City level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now explore our data if we group them according to Geographic Level and Income Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's do a quick pairplot correlation analysis while differentiating the colors by Geographic Level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_merged, hue = \"Geographic Level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_levels = df_merged['Geographic Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in geo_levels:\n",
    "    sub_df = df_merged.loc[df_merged['Geographic Level'] == level,['Population', 'Poverty Incidence','Case Per Capita']]\n",
    "    print(level)\n",
    "    #print('\\n')\n",
    "    print(sub_df_cases_raw.corr())\n",
    "    print('\\n\\n')\n",
    "    g = sns.pairplot(sub_df)\n",
    "    g.fig.suptitle(level, y=1.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see no strong correlation. Relatively, the strongest correlation we see is with Poverty Incidence at -0.52, a moderately negative correlation between Poverty Incidence and Case Per Capita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the effects if we group them by Income Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_merged, hue = \"Income Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_classes = df_merged['Income Classification'].unique()\n",
    "\n",
    "for level in income_classes:\n",
    "    sub_df = df_merged.loc[df_merged['Income Classification'] == level,['Population', 'Poverty Incidence','Case Per Capita']]\n",
    "    print(level)\n",
    "    #print('\\n')\n",
    "    print(sub_df_cases_raw.corr())\n",
    "    print('\\n\\n')\n",
    "    g = sns.pairplot(sub_df)\n",
    "    g.fig.suptitle(level, y=1.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see no strong correlation. Although only moderate, we do see a moderate positive correlation between Population and Cases per Capita when you're a 6th Class City at 0.64. We also see a moderate negative correlation between Poverty Incidence and Cases per Capita when you are an unclassified city or municipality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most the of cases occur in Metro Manila, let us see if there's Poverty Incidence is a strong predictor of Cases Per Capita in the Metro Manila Area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that cities in the National Capital Region of Metro Manila has a PSGC of 130000000 or more. Limiting our dataset to Metro Manila cities we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#psgc_mm = ['133900000', '137401000', '137402000', '137403000', '137404000', '137405000', '137501000', '137502000', '137503000', '137504000', '137601000', '137602000', '137603000', '137604000', '137606000', '137605000', '137607000']\n",
    "psgc_mm = ['137401000', '137402000', '137403000', '137404000', '137405000', '137501000', '137502000', '137503000', '137504000', '137601000', '137602000', '137603000', '137604000', '137606000', '137605000', '137607000']\n",
    "df_mm = df_merged.loc[psgc_mm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_mm.corr(),annot=True,lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mm.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see no strong correlation. We also see a moderate negative correlation between Population and Cases per Capita for the largest cities in the Philippines and the epicenter of the pandemic.\n",
    "\n",
    "For now, we can conclude that Poverty Incidence is not a strong predictor of severity as measured by Cases Per Capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy variables\n",
    "\n",
    "#change UNK for different columns\n",
    "for columns in df_merged.columns:\n",
    "    print(f'Number of Unknowns for Column {columns} = {sum(df_merged[columns] == \"UNK\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.get_dummies(df_merged, \n",
    "               columns = ['Geographic Level', 'Income Classification'], \n",
    "               prefix = ['GL','IC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged[['Name', 'Population', 'Poverty Incidence', 'GL_City', \n",
    "     'GL_Mun', 'GL_SubMun', 'IC_1st', 'IC_2nd','IC_3rd', 'IC_4th', \n",
    "     'IC_5th', 'IC_6th', 'IC_Special', 'IC_UNK','Case Per Capita']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check histogram of population\n",
    "df_merged['Population'][df_merged['IC_3rd'] == 1].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize population\\\n",
    "ss = StandardScaler()\n",
    "df_merged['Population Normalized'] = ss.fit_transform(df_merged[['Population']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.corr().loc['Case Per Capita']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target variable\n",
    "y = df_merged['Case Per Capita']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merged[['Population Normalized', 'Poverty Incidence', 'GL_City', 'GL_Mun', 'GL_SubMun', 'IC_1st', 'IC_2nd','IC_3rd', 'IC_4th', 'IC_5th', 'IC_6th', 'IC_Special', 'IC_UNK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2)\n",
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting a linear model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lm.predict(X_valid)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_pred, y_valid))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdgCV = RidgeCV(alphas=[0.01,0.1,1,10,100,1000], cv=5)\n",
    "rdgCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rdgCV.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg = Ridge(alpha=10)\n",
    "rdg.fit(X_train, y_train)\n",
    "rdg.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rdg.predict(X_valid)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_pred, y_valid))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_jobs=-1, n_estimators=100)\n",
    "rfr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.score(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfr.predict(X_valid)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_pred, y_valid))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.coef_)\n",
    "print(np.argmax(lm.coef_))\n",
    "print(df_merged.columns[np.argmax(lm.coef_)])\n",
    "print(rdgCV.coef_)\n",
    "print(np.argmax(rdgCV.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.fit(X_train,y_train)\n",
    "\n",
    "y_lm_pred = lm.predict(X_train)\n",
    "y_rdgCV_pred = rdgCV.predict(X_train)\n",
    "y_rfr_pred = rfr.predict(X_train)\n",
    "\n",
    "print('-----training score ---')\n",
    "print(lm.score(X_train, y_train))\n",
    "print(rdgCV.score(X_train, y_train))\n",
    "print(rfr.score(X_train, y_train))\n",
    "print('----Validation score ---')\n",
    "print(lm.score(X_valid, y_valid))\n",
    "print(rdgCV.score(X_valid, y_valid))\n",
    "print(rfr.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_merged.corr().loc['Case Per Capita'], robust = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "section where you discuss the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "section where you discuss any observations you noted and any recommendations you can make based on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "section where you conclude the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras below\n",
    "## Next Steps\n",
    "* merge geojson in main dataframe\n",
    "* calculate distance from manila\n",
    "* determine correlation between distance from manila\n",
    "* do same analysis as earlier with baranggay level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_remove = 'Geographic Level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_new = list(sub_df_cases_raw.columns)\n",
    "col_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_merged[['Geographic Level','Population','Poverty Incidence','Case Per Capita']], hue = 'Geographic Level',\n",
    "            diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_by_level(dataframe, variable):\n",
    "    for level in geo_levels:\n",
    "        sub_df = df_merged.loc[df_merged['Geographic Level'] == level,['Population', 'Poverty Incidence','Case Per Capita']]\n",
    "    print(level)\n",
    "    print('\\n')\n",
    "    #print(sub_df_cases_raw.corr().loc['Case Per Capita'])\n",
    "    sns.pairplot(sub_df)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in geo_levels:\n",
    "    sub_df = df_merged.loc[df_merged['Geographic Level'] == level,['Population', 'Poverty Incidence','Case Per Capita']]\n",
    "    print(level)\n",
    "    print('\\n')\n",
    "    #print(sub_df_cases_raw.corr().loc['Case Per Capita'])\n",
    "    sns.pairplot(sub_df)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['Geographic Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.loc[df_merged['Geographic Level'] == 'Mun',['Population', 'Poverty Incidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in df_merged['Geographic Level'].unique():\n",
    "    sub_df = df_merged.loc[df_merged['Geographic Level'] == level,['Population', 'Poverty Incidence','Case Per Capita']]\n",
    "    print(level)\n",
    "    print('\\n')\n",
    "    #print(sub_df_cases_raw.corr().loc['Case Per Capita'])\n",
    "    sns.pairplot(sub_df)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['Income Classification'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
